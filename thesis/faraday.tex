%!tex root=./thesis.tex
\chapter{Faraday Complexity}
\label{cha:faraday-faraday}

This chapter is based on my to-be-submitted paper \emph{Interpretable Faraday Complexity Classification}, by M. J. Alger, C. S. Ong, J. D. Livingston, J. L. Nabaglo, N. M. McClure-Griffiths, and O. I. Wong.

  Faraday complexity describes whether a spectropolarimetric observation has simple or complex magnetic structure. Quickly determining the Faraday complexity of a spectropolarimetric observation is important for processing large, polarised radio surveys. Finding simple sources lets us build rotation measure grids, and finding complex sources lets us follow these sources up with slower analysis techniques or further observations. In this chapter, we introduce five features that can be used to train simple, interpretable machine learning classifiers for estimating Faraday complexity. We train logistic regression and extreme gradient boosted tree classifiers on simulated polarised spectra using our features, analyse their behaviour, and demonstrate our features are effective for both simulated and real data. With 95 per cent accuracy on simulated ASKAP data and 90 per cent accuracy on simulated ATCA data, our method performs comparably to state-of-the-art convolutional neural networks while being simpler and easier to interpret. Logistic regression trained with our features behaves sensibly on real data and its outputs are useful for sorting polarised sources by apparent Faraday complexity.

  M.J.A. and J.D.L. were supported by the Australian Government Research Training Program. M.J.A. was supported by the Astronomical Society of Australia.

\section{Introduction}
\label{sec:faraday-intro}

  As polarised radiation from distant galaxies makes its way to us, magnetised plasma along the way can cause the polarisation angle to change due to the Faraday effect. The amount of rotation depends on the squared wavelength of the radiation, and the rotation per squared wavelength is called the Faraday depth. Multiple Faraday depths may exist along one line-of-sight, and if a polarised source is observed at multiple wavelengths then these multiple depths can be disentangled. This can provide insight into the polarised structure of the source.

  Faraday rotation measure synthesis (RM synthesis) is a technique for decomposing a spectropolarimetric observation into flux at its Faraday depths $\phi$, the resulting distribution of depths being called a `Faraday dispersion function' (FDF) or a `Faraday spectrum'. It was introduced by \citet{brentjens_faraday_2005} as a way to rapidly and reliably analyse the polarisation structure of complex and high-Faraday depth polarised observations.

  A `Faraday simple' observation is one for which there is only one Faraday depth, and in this simple case the Faraday depth is also known as a `rotation measure' (RM). All Faraday simple observations can be modelled as a polarised source with a single set of thermal plasma \citep[a `Faraday screen';][]{brentjens_faraday_2005,anderson_broadband_2015} between the observer and the source. A `Faraday complex' observation is one which is not Faraday simple, and may differ from a Faraday simple source due to plasma emission or composition of multiple screens \citep{brentjens_faraday_2005}. The complexity of a source tells us important details about the polarised structure of the source and along the line-of-sight, such as whether the intervening medium emits polarised radiation, or whether there are turbulent magnetic fields or different electron densities in the neighbourhood. The complexity of nearby sources taken together can tell us about the magneto-ionic structure of the galactic and intergalactic medium between the sources and us as observers. \autoref{fig:simple-fdf} and \autoref{fig:complex-fdf} show an example of a simple and a complex FDF respectively, as well as the corresponding polarised observation.

  Identifying when an observation is Faraday complex is an important problem in polarised surveys \citep{sun15comparison}, and with surveys now being conducted larger than ever before, methods that can quickly characterise Faraday complexity en masse are increasingly useful. Being able to identify which sources are simple lets us produce a reliable rotation measure grid from background sources, and being able to identify which sources might be complex allows us to find sources to follow-up with slower polarisation analysis methods that may require manual oversight. In this chapter, we introduce a set of five simple, interpretable features representing polarised spectra, use these features to train machine learning classifiers to identify Faraday complexity, and demonstrate their effectiveness on real and simulated data. We construct our features by comparing observed polarised sources to idealised polarised sources. The features are intuitive and can be estimated from real FDFs.

  % We demonstrate the effectiveness of our method on both simulated and real data. Using simulated data, we compare our method to the state-of-the-art CNN Faraday complexity estimation methods.

  \autoref{sec:faraday-background} provides a background to our work, including a summary of prior work and our assumptions on FDFs. \autoref{sec:faraday-approach} describes our approach to the Faraday complexity problem. \autoref{sec:faraday-experiment-classification} explains how we trained and evaluated our method. Finally, \autoref{sec:faraday-discussion} discusses these results.

\section{Faraday Complexity}
\label{sec:faraday-background}

    Faraday complexity is an observational property of a source: if multiple Faraday depths are observed within the same apparent source (e.g. due to multiple lines-of-sight being combined within a beam), then the source is complex, and otherwise it is simple. A source composed of multiple Faraday screens may be consistent with many other models \citep{sun15comparison}, including simple sources, so there is some overlap between simple and complex sources. Faraday thickness is also a source of Faraday complexity: when the intervening medium between a polarised source and the observer also emits polarised light, the FDF cannot be characterised by a simple Faraday screen. As discussed in \autoref{sec:faraday-fdfs} we defer Faraday thick sources to future work. In this section we summarise existing methods of Faraday complexity estimation and explain our assumptions and model of simple and complex polarised FDFs.

  \subsection{Prior work}
  \label{sec:faraday-prior-work}

      There are multiple ways to estimate Faraday complexity, including detecting non-linearity in $\chi(\lambda^2)$ \citep{goldstein84faraday}, change in fractional polarisation as a function of frequency \citep{farnes14broadband}, non-sinusoidal variation in fractional polarisation in Stokes $Q$ and $U$ \citep{osullivan12agn}, counting components in the FDF \citep{law11faraday}, minimising the Bayesian information criterion (BIC) over a range of simple and complex models \citep[called `QU fitting';][]{osullivan_broad-band_2017}, the method of Faraday moments \citep{anderson_broadband_2015,Brown11report}, and deep convolutional neural network classifiers \citep[CNNs;][]{brown_classifying_2018}. See \citet{sun15comparison} for a comparison of these methods.

      The most common approaches to estimating complexity are QU fitting \citep[e.g.][]{osullivan_broad-band_2017} and Faraday moments \citep[e.g.][]{anderson_broadband_2015}. To our knowledge there is currently no literature examining the accuracy of QU fitting when applied to complexity classification specifically, though \citet{miyashita19qu} analyse its effectiveness on identifying the structure of two-component sources. \citet{Brown11report} suggested Faraday moments as a method to identify complexity, a method later used by \citet{farnes14broadband} and \citet{anderson_broadband_2015}, but again no literature examines the accuracy. CNNs are the current state-of-the-art with an accuracy of 94.9 per cent \citep{brown_classifying_2018} on simulated ASKAP Band 1 and 3 data, and we will compare our results to this method.

  \subsection{Assumptions on Faraday dispersion functions}
  \label{sec:faraday-fdfs}

    \begin{figure}
      \includegraphics[width=\linewidth]{faraday-images/spectra_simple.pdf}
      \caption{A simple FDF and its corresponding polarised spectra: (a) groundtruth FDF $F$, (b) noise-free polarised spectrum $P$, (c) noisy observed FDF $\hat F$, (d) noisy polarised spectrum $\hat P$. Blue and orange mark real and imaginary components respectively.}
      \label{fig:simple-fdf}
    \end{figure}

    \begin{figure}
      \includegraphics[width=\linewidth]{faraday-images/spectra.pdf}
      \caption{A complex FDF and its corresponding polarised spectra: (a) groundtruth FDF $F$, (b) noise-free polarised spectrum $P$, (c) noisy observed FDF $\hat F$, (d) noisy polarised spectrum $\hat P$. Blue and orange mark real and imaginary components respectively.}
      \label{fig:complex-fdf}
    \end{figure}

    Before we can classify FDFs as Faraday complex or Faraday simple, we need to define FDFs and any assumptions we make about them. An FDF is a function that maps Faraday depth $\phi$ to complex polarisation. It is the distribution of Faraday depths in an observed polarisation spectrum. For a given observation, we assume there is a true, noise-free FDF $F$ composed of at most two Faraday screens. This accounts for most actual sources \citep{anderson_broadband_2015} and extension to three screens would cover most of the remainder---\citet{osullivan_broad-band_2017} found that 89 per cent of their sources were best explained by two or less screens, while the remainder were best explained by three screens. We model the screens by Dirac delta distributions:
    \begin{equation}
        \label{eq:faraday-true-fdf}
        F(\phi) = A_0 \delta(\phi - \phi_0) + A_1 \delta(\phi - \phi_1).
    \end{equation}
    $A_0$ and $A_1$ are the polarised flux of each Faraday screen, and $\phi_0$ and $\phi_1$ are the Faraday depths of the respective screens. With this model, a Faraday simple source is one which has $A_0 = 0$, $A_1 = 0$, or $\phi_0 = \phi_1$. By using delta distributions to model each screen, we are assuming that there is no internal Faraday dispersion (which is typically associated with diffuse emission rather than the mostly-compact sources we expect to find in wide-area polarised surveys). $F$ generates a polarised spectrum of the form shown in \autoref{eq:faraday-true-pol}:
    \begin{equation}
        \label{eq:faraday-true-pol}
        P(\lambda^2) = A_0 e^{2i\phi_0\lambda^2} + A_1 e^{2i\phi_1\lambda^2}.
    \end{equation}
    Such a spectrum would be observed as noisy samples from a number of squared wavelengths $\lambda^2_j, j \in [1, \dots, D]$. We model this noise as a complex Gaussian with standard deviation $\sigma$ and call the noisy observed spectrum $\hat P$:
    \begin{equation}
      \label{eq:faraday-noisy-pol}
      \hat P(\lambda_j^2) \sim \mathcal N(P(\lambda^2_j), \sigma^2).
    \end{equation}
    The constant variance of the noise is a simplifying assumption which may not hold for real data, and exploring this is a topic for future work. By performing RM synthesis \citep{brentjens_faraday_2005} on $\hat P$ with uniform weighting we arrive at an observed FDF:
    \begin{equation}
      \label{eq:faraday-rm-synthesis}
      \hat F(\phi) = \frac{1}{D} \sum_{j = 1}^D \hat P(\lambda^2_j) e^{-2i\phi\lambda^2_j}.
    \end{equation}
    Examples of $F$, $\hat F$, $P$, and $\hat P$ for simple and complex observations are shown in \autoref{fig:simple-fdf} and \autoref{fig:complex-fdf} respectively. Note that there are two reasons that the observed FDF $\hat F$ does not match the groundtruth FDF $F$. The first is the noise in $\hat P$. The second arises from the incomplete sampling of $\hat P$.

    We do not consider external or internal Faraday dispersion in this work. External Faraday dispersion would broaden the delta functions of \autoref{eq:faraday-true-fdf} into peaks, and internal Faraday dispersion would broaden them into top-hat functions. All sources have at least a small amount of dispersion as the Faraday depth is a bulk property of the intervening medium and is subject to noise, but the assumption we make is that this dispersion is sufficiently small that the groundtruth FDFs are well-modelled with delta functions. Faraday thick sources would also invalidate our assumptions, and we assume that there are none in our data as Faraday thickness is hard to observe anyway \citeneeded{}. Nevertheless some external Faraday dispersion would be covered by our model, as depending on observing parameters Faraday thick sources may appear as two screens \citep{vaneck17faraday}.

    To simulate observed FDFs we follow the method of \citet{brown_classifying_2018}, which we describe in \autoref{sec:faraday-simulating}.

\section{Classification approach}
\label{sec:faraday-approach}

  The Faraday complexity classification problem is as follows: Given an FDF $\hat F$, is it Faraday complex or Faraday simple? In this section we describe the features that we have developed to address this problem, which can be used in any standard machine learning classifier. We trained two classifiers on these features, which we describe here also.

  \subsection{Features}
  \label{sec:faraday-scores-method}

    Our features are based on a simple idea: all simple FDFs look essentially the same, up to scaling and translation, while complex FDFs may deviate. A noise-free peak-normalised simple FDF $\hat F_{\mathrm{simple}}$ has the form
    \begin{align}
        \label{eq:faraday-f-simple}
        \hat F_{\mathrm{simple}}(\phi; \phi_s) &= R(\phi - \phi_s).
    \end{align}
    $\phi_s$ traces out a curve in the space of all possible FDFs. In other words, $\hat F_{\mathrm{simple}}$ is a manifold parametrised by $\phi_s$. Our features are derived from relating an observed FDF to the manifold of simple FDFs (the `simple manifold'). We can characterise an FDF by its distance to the simple manifold using some distance measure $D_f$:
    \begin{equation}
        \label{eq:faraday-complexity-model}
        \varsigma_f(\hat F) = \min_{\phi_s \in \mathbb{R}} D_f\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_s)}.
    \end{equation}
    This distance has nice properties, as it is:
    \begin{itemize}
        \item invariant over changes in complex phase,
        \item translationally invariant in Faraday depth,
        \item zero for Faraday simple sources (i.e. when $A_0 = 0$, $A_1 = 0$, or $\phi_0 = \phi_1$) when there is no noise,
        \item symmetric in components (i.e. swapping $A_0 \leftrightarrow A_1$ and $\phi_0 \leftrightarrow \phi_1$ should not change the distance),
        \item increasing as $A_0$ and $A_1$ become closer to each other, and
        \item increasing as screen separation $|\phi_0 - \phi_1|$ increases over a large range.
    \end{itemize}
    Our features are constructed from this distance and its minimiser. In other words
    we look for the simple FDF $\hat{F}_{\mathrm{simple}}$ that is ``closest'' to the observed FDF $\hat{F}$.
    The minimiser $\phi_s$ is the Faraday depth of the simple FDF.

    While we could choose any distance that operates on functions, we used the 2-Wasserstein ($W_2$) distance \eqref{eq:faraday-W2-distance} and the Euclidean distance \eqref{eq:faraday-Euclidean-distance}. The $W_2$ distance operates on probability distributions and can be thought of as the minimum cost to `move' one probability distribution to the other, where the cost of moving one unit of probability mass is the squared distance it is moved. Under $W_2$ distance, the minimiser $\phi_w$ in \autoref{eq:faraday-complexity-model} can be interpreted as the Faraday depth that the FDF $\hat F$ would be observed to have if its complexity was unresolved (i.e. the weighted mean of its components). The Euclidean distance is the square root of the least-squares loss which is often used for fitting $\hat{F}_{\mathrm{simple}}$ to the FDF $\hat F$. Under Euclidean distance, the minimiser $\phi_s$ is equivalent to the depth of the best-fitting single component under assumption of Gaussian noise in $\hat F$.
    We calculated the $W_2$ distance using \texttt{Python Optimal Transport} \citep{flamary17pot}, and we calculated the Euclidean distance using \texttt{scipy.spatial.distance.euclidean} \citep{scipy2020}.
    Further intuition about the two distances is provided in \autoref{sec:faraday-interpreting-distances}.

    We denote by $\phi_w$ and $\phi_e$, the Faraday depth of the simple FDF that minimises the respective distances
    (2-Wasserstein and Euclidean).
    \begin{align*}
       \phi_w &= \underset{\phi_w}{\mathrm{argmin}}\ D_{W_2}\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_w)},\\
       \phi_e &= \underset{\phi_e}{\mathrm{argmin}}\ D_E\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_e)}.
     \end{align*}
     These features are depicted on an example FDF in \autoref{fig:features-on-fdf}.
     For simple observed FDFs, the fitted Faraday depths $\phi_w$ and $\phi_e$ both tend to be
     close to the peak of the observed FDF. However for complex observed FDFs, $\phi_w$ tends
     to be at the average depth between the two major peaks of the observed FDF, being closer
     to the higher peak. For notation convenience, we denote the Faraday depth of the
     observed FDF that has largest magnitude as $\phi_a$, i.e.
     \begin{equation*}
       \phi_a = \underset{\phi_a}{\mathrm{argmax}}\ |\hat F(\phi_a)|,\\
     \end{equation*}
     Note that in practice $\phi_a \approx \phi_e$.
     For complex observed FDFs, the values of Faraday depths $\phi_w$ and $\phi_a$ tend
     to differ (essentially by a proportion of the location of the second screen).
     The difference between $\phi_w$ and $\phi_a$ therefore provides useful information
     to identify complex FDFs.
     When the observed FDF is simple, the 2-Wasserstein fit will overlap significantly,
     hence the observed magnitudes $\hat F(\phi_w)$ and $\hat F(\phi_a)$ will be similar.
     However, for complex FDFs $\phi_w$ and $\phi_a$ are at different depths,
     leading to different values of $\hat F(\phi_w)$ and $\hat F(\phi_a)$.
     Therefore the magnitudes of the observed FDFs at the depths $\phi_w$ and $\phi_a$
     indicate how different the observed FDF is from a simple FDF.

    \begin{figure}
      \centering
      \includegraphics[width=\linewidth]{faraday-images/features_on_graph.pdf}
      \caption{\label{fig:features-on-fdf} An example of how an observed FDF $\hat F$ relates to our features. $\phi_w$ is the $W_2$-minimising Faraday depth, and $\phi_a$ is the $\hat F$-maximising Faraday depth (approximately equal to the Euclidean-minimising Faraday depth). The remaining two features are the $W_2$ and Euclidean distances between the depicted FDFs.}
    \end{figure}

    In summary, we provide the following features to the classifier:
    \begin{itemize}
      \item $\log |\phi_w - \phi_a|$,
      \item $\log \hat F(\phi_w)$,
      \item $\log \hat F(\phi_a)$,
      \item $\log D_{W_2}\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_w)}$,
      \item $\log D_{E}\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_e)}$,
    \end{itemize}
    where $D_E$ is the Euclidean distance, $D_{W_2}$ is the $W_2$ distance, $\phi_a$ is the Faraday depth of the FDF peak, $\phi_w$ is the minimiser for $W_2$ distance, and $\phi_e$ is the minimiser for Euclidean distance.

    \subsection{Interpreting distances}
    \label{sec:faraday-interpreting-distances}

    Interestingly, in the case where there is no RMSF, \autoref{eq:faraday-complexity-model} with $W_2$ distance reduces to the Faraday moment already in common use:
    \begin{align}
        D_{W_2}(F) &= \min_{\phi_w \in \mathbb{R}} D_{W_2}\infdivx{F(\phi)}{F_{\mathrm{simple}}(\phi; \phi_w)}\label{eq:faraday-W2-distance}\\
            &= \left(\frac{A_0A_1}{(A_0 + A_1)^2} (\phi_0 - \phi_1)^2\right)^{1/2}.
    \end{align}
    See \autoref{sec:faraday-w2-to-faraday-moments} for the corresponding calculation. In this sense, the $W_2$ distance can be thought of as a generalised Faraday moment, and conversely an interpretation of Faraday moments as a distance from the simple manifold in the case where there is no RMSF. Euclidean distance behaves quite differently in this case, and the resulting distance measure is totally independent of Faraday depth:
    \begin{align}
        D_{E}(F) &= \min_{\phi_e \in \mathbb{R}} D_E\infdivx{F(\phi)}{F_{\mathrm{simple}}(\phi; \phi_e)}\label{eq:faraday-Euclidean-distance}\\
            &= \sqrt{2} \frac{\min(A_0, A_1)}{A_0 + A_1}.
    \end{align}
    See \autoref{sec:faraday-euclidean-calculation} for the corresponding calculation.


  \subsection{Classifiers}
  \label{sec:faraday-classifiers}

    We trained two classifiers on simulated observations using these features: logistic regression (LR) and extreme gradient boosted trees (XGB). These classifiers are useful together for understanding Faraday complexity classification. LR is a linear classifier that is readily interpretable by examining the weights it applies to each feature. XGB is a powerful off-the-shelf non-linear ensemble classifier. We used the \texttt{scikit-learn} implementation of LR and we use the \texttt{XGBoost} library for XGB. We optimised hyperparameters for XGB using a fork of \texttt{xgboost-tuner} \footnote{\url{https://github.com/chengsoonong/xgboost-tuner}} as utilised by \citet{zhu20mutagenic}. We used 1~000 iterations of randomised parameter tuning and the hyperparameters we found are tabulated in \autoref{tab:hyperparameters-xgb}. We optimised hyperparameters for LR using a 5-fold cross-validation grid search implemented in \texttt{sklearn.model\textunderscore{}selection.GridSearchCV}. The resulting hyperparameters are tabulated in \autoref{tab:hyperparameters-lr}.

\section{Experimental method and results}
\label{sec:faraday-experiment-classification}

  We applied our classifiers to classify simulated (\autoref{sec:faraday-cnn-comparison} and \ref{sec:results-simulated}) and real (\autoref{sec:faraday-results-observed}) FDFs. We replicated the experimental setup of \citet{brown_classifying_2018} for comparison with the state-of-the-art CNN classification method, and we also applied our method to 142 real FDFs observed with the Australia Telescope Compact Array (ATCA) from Livingston et al. (in prep.) and \citet{osullivan_broad-band_2017}.

  \subsection{Data}

  \subsubsection{Simulated training and validation data}
  \label{sec:faraday-simulated-training-data}

    Our classifiers were trained and validated on simulated FDFs. We produced two sets of simulated FDFs, one for comparison with the state-of-the-art method in the literature and one for application to our observed FDFs (described in \autoref{sec:faraday-observational-data}). We refer to the former as the `ASKAP' dataset as it uses frequencies from the Australian Square Kilometre Array Pathfinder 12-antenna early science configuration. These frequencies included 900 channels from 700--1300 and 1500--1800~MHz and were used to generate simulated training and validation data by \citet{brown_classifying_2018}. We refer to the latter as the `ATCA' dataset as it uses frequencies from the 1--3~GHz configuration of the ATCA. These frequencies included 394 channels from 1.29--3.02~GHz and match our real data. We simulated Faraday depths from $-50$ to $50$ rad~m$^{-2}$ for the `ASKAP' dataset (matching Brown) and $-500$ to $500$ for the `ATCA' dataset.

    For each dataset, we simulated 100~000 FDFs, approximately half simple and half complex. We randomly allocated half of these FDFs to a training set and reserved the remaining half for validation. Each FDF had complex Gaussian noise added to the corresponding polarisation spectrum. For the `ASKAP' dataset, we sampled the standard deviation of the noise uniformly between 0 and $\sigma_{\max} = 0.333$, matching the dataset of \citet{brown_classifying_2018}.
    For the `ATCA' dataset, we fit a log-normal distribution to the standard deviations of O'Sullivan's data \citep{osullivan_broad-band_2017} from which we sampled our values of $\sigma$:
    \begin{equation}
      \sigma \sim \frac{1}{0.63 \sqrt{2 \pi} \sigma} \exp \left(-\frac{\log\left(50 \sigma - 0.5\right)^2}{2 \times 0.63^2}\right)
    \end{equation}


  \subsubsection{Observational data}
  \label{sec:faraday-observational-data}

    We used two real datasets containing a total of 142 sources: 42 polarised spectra from Livingston et al. (in prep.) and 100 polarised spectra from \citet{osullivan_broad-band_2017}. These datasets were observed in similar frequency ranges on the same telescope (with different binning), but are in different parts of the sky. The Livingston data were taken near the Galactic Centre, and the O'Sullivan data were taken away from the plane of the Galaxy. There are more Faraday complex sources near the Galactic Centre compared to more Faraday simple sources away from the plane of the Galaxy (Livingston et al.). The similar frequency channels used in the two datasets result in almost identical RMSFs over the Faraday depth range we considered (-500 to 500 rad m$^{-2}$), so we expected that the classifiers would work equally well on both datasets with no need to re-train. We discarded the 26 Livingston sources with modelled Faraday depths outside of this Faraday depth range, which we do not expect to affect the applicability of our methods to wide-area surveys because these fairly high depths are not common.

    Livingston et al. (in prep) used RM-CLEAN \citep{heald09faraday} to identify significant components in their FDFs. Some of these components had very high Faraday depths up to 2000 rad m$^{-2}$, but we chose to ignore these components in this chapter as they are much larger than might be expected in a wide-area survey like POSSUM. They used the second Faraday moment \citep{Brown11report} to estimate Faraday complexity, with Faraday depths determined using \texttt{scipy.signal.find\textunderscore{}peaks} on the cleaned FDFs, with a cutoff of 7 times the noise of the polarised spectrum. Using this method, they estimated that 89 per cent of their sources were Faraday complex i.e. had a Faraday moment greater than 0.

    \citet{osullivan_broad-band_2017} used the QU-fitting and model selection technique described in \citet{osullivan12agn}. The QU-fitting models contained up to three Faraday screen components as well as a term for internal and external Faraday dispersion. We ignore the Faraday thickness and dispersion for the purposes of this chapter, as most sources were not found to have Faraday thickness and dispersion is beyond the scope of our current work. 37 sources had just one component, 52 had two, and the remaining 11 had three.

  \subsection{Results on ``ASKAP'' dataset}
  \label{sec:faraday-cnn-comparison}

    The accuracy of the LR and XGB classifiers on the ``ASKAP'' testing set was 94.4 and 95.1 per cent respectively. The confusion matrices are shown in \autoref{tab:cm-lr-askap12} and \autoref{tab:cm-xgb-askap12}. These results are very close to the CNN presented by \citet{brown_classifying_2018}, with a slightly higher true negative rate and a slightly lower true positive rate (recalling that positive sources are complex, and negative sources are simple). The accuracy of the CNN was 94.9, slightly lower than our XGB classifier and slightly higher than our LR classifier. Both of our classifiers therefore produce similar classification performance to the CNN, with faster training time and easier interpretation.

  \subsection{Results on ``ATCA'' dataset}
  \label{sec:faraday-results-simulated}

    The accuracy of the LR and XGB classifiers on the ``ATCA'' dataset was 89.2 and 90.5 per cent respectively. The major differences between the ``ATCA'' and the ``ASKAP'' experiments are the range of the simulated Faraday depths and the distribution of noise levels. The ``ASKAP'' dataset, to match past CNN work, only included depths from $-50$ to $50$ rad m$^{-2}$, while the ``ATCA'' dataset includes depths from $-500$ to $500$ rad m$^{-2}$. The confusion matrices are shown in \autoref{tab:cm-lr} and \autoref{tab:cm-xgb}.

    \begin{figure}
      \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{faraday-images/mean_xgb_prediction_dphi_amp.pdf}
        \caption{\label{fig:mean-xgb-pred}}
      \end{subfigure}
      \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{faraday-images/mean_lr_prediction_dphi_amp.pdf}
        \caption{\label{fig:mean-lr-pred}}
      \end{subfigure}
      \caption{\label{fig:amps-dphi-mean} Mean prediction as a function of component depth separation and minimum component amplitude for (a) XGB and (b) LR.}
    \end{figure}

    As we know the true Faraday depths of the components in our simulation, we can investigate the behaviour of these classifiers as a function of physical properties. \autoref{fig:amps-dphi-mean} shows the mean classifier prediction as a function of component depth separation and minimum component amplitude. This is tightly related to the mean accuracy, as the entire plot domain contains complex spectra besides the left and bottom edge: by setting the threshold to a value on this plot, the accuracy will be one hundred per cent on the non-edge for all higher values.

  \subsection{Results on observed FDFs}
  \label{sec:faraday-results-observed}

    % \begin{figure*}
    %   \centering
    %   \begin{subfigure}{0.45\linewidth}
    %     \includegraphics[width=\linewidth]{faraday-images/livingston_false_positive.pdf}
    %     \caption{Predicted complex.}
    %     \label{fig:livingston-false-positive}
    %   \end{subfigure}%
    %   \begin{subfigure}{0.45\linewidth}
    %     \includegraphics[width=\linewidth]{faraday-images/livingston_false_negative.pdf}
    %     \caption{Predicted simple.}
    %     \label{fig:livingston-false-negative}
    %   \end{subfigure}
    %   \begin{subfigure}{0.45\linewidth}
    %     \includegraphics[width=\linewidth]{faraday-images/osullivan_false_positive.pdf}
    %     \caption{Predicted complex.}
    %   \end{subfigure}%
    %   \begin{subfigure}{0.45\linewidth}
    %     \includegraphics[width=\linewidth]{faraday-images/osullivan_false_negative.pdf}
    %     \caption{Predicted simple.}
    %   \end{subfigure}
    %   \caption{Randomly-selected misclassified FDFs. (a) and (b) are from the Livingston dataset, and (c) and (d) are from the O'Sullivan dataset. (a) and (c) were misclassified as complex while (b) and (d) were misclassified as simple.}
    %   \label{fig:misclassified}
    % \end{figure*}

    \begin{figure*}
      \centering
      \includegraphics[width=\linewidth]{faraday-images/pca_with_overlay.pdf}
      \caption{Principal component analysis for simulated data (coloured dots) with observations overlaid (black-edged circles). Observations are coloured by their XGB or LR estimated probability of being complex, with blue indicating `most simple' and pink indicating `most complex'.}
      \label{fig:pca}
    \end{figure*}
    \begin{figure}
      \centering
      \includegraphics[width=\linewidth]{faraday-images/pc_complex_curves.pdf}
      \caption{Estimated rates of Faraday complexity for the Livingstone and O'Sullivan datasets as functions of threshold. The horizontal lines indicate the rates of Faraday complexity estimated by Livingston and O'Sullivan respectively.}
      \label{fig:complexity-rates}
    \end{figure}

    We used the LR and XGB classifiers which were trained on the ATCA simulation to estimate the probability that our 142 observed FDFs (\autoref{sec:faraday-observational-data}) were Faraday complex. As these classifiers were trained on simulated data, they face the issue of the `domain gap': the distribution of samples from a simulation differs from the distribution of real sources, and this affects performance on real data. Solving this issue is called `domain adaptation' and how to do this is an open research question in machine learning \citep{zhang2019transfer,pan10transfer}. Nevertheless, the features of our observations mostly fall in the same region of feature space as the simulations (\autoref{fig:pca}) and so we expect reasonably good domain transfer.

    Two apparently complex sources in the Livingston sample are classified as simple with high probability by XGB. These outliers are on the very edge of the training sample (\autoref{fig:pca}) and the underdensity of training data here is likely the cause of this issue. LR does not suffer the same issue, producing plausible predictions for the entire dataset, and these sources are instead classified as complex with high probability.

    With a threshold of 0.5, LR predicted that 96 and 83 per cent of the Livingston and O'Sullivan sources were complex respectively. This is in line with expectations that the Livingston data should have more Faraday complex sources than the O'Sullivan data due to their location near the Galactic Centre. XGB predicted that 93 and 100 per cent of the Livingston and O'Sullivan sources were complex respectively. Livingston et al. (in prep) found that 90 per cent of their sources were complex, and \citet{osullivan_broad-band_2017} found that 64 per cent of their sources were complex. This suggests that our classifiers are overestimating complexity, though it could also be the case that the methods used by Livingston and O'Sullivan underestimate complexity. Modifying the prediction threshold from 0.5 changes the estimated rate of Faraday complexity, and we show the estimated rates against threshold for both classifiers in \autoref{fig:complexity-rates}. We suggest that this result is indicative of our probabilities being uncalibrated, and a higher threshold should be chosen in practice. We chose to keep the threshold at 0.5 as this had the highest accuracy on the simulated validation data. The very high complexity rates of XGB and two outlying classifications indicate that the XGB classifier may be overfitting to the simulation and that it is unable to generalise across the domain gap.

    \autoref{fig:all-observed-fdfs-lr} and \autoref{fig:all-observed-fdfs-xgb} show every observed FDF ordered by estimated Faraday complexity, alongside the models predicted by Livingston and O'Sullivan, for LR and XGB respectively. There is a clear visual trend of increasingly complex sources with increasing predicted probability of being complex. %The complex FDFs in the Livingston dataset that were identified as simple by the classifier tend to have very different component amplitudes and a very high signal-to-noise main peak, while the simple FDFs identified as complex tend to be very noisy.

\section{Discussion}
\label{sec:faraday-discussion}

  % \todo{Changing the bias of the classifiers would allow us to optimise for high precision or high recall depending on the use case of the classifier, but we optimised for maximum accuracy here.}

  On simulated data (\autoref{sec:faraday-results-simulated}) we achieve state-of-the-art accuracy. Our results on observed FDFs show that our classifiers produce plausible results, with \autoref{fig:all-observed-fdfs-lr} and \autoref{fig:all-observed-fdfs-xgb} showing a clear trend of apparent complexity. Some issues remain: we discuss the intrinsic overlap between simple and complex FDFs in \autoref{sec:faraday-overlap} and the limitations of our method in \autoref{sec:faraday-limitations}.

  % \subsection{Interpretable classification}

  %   Our classifiers are interpretable. The features are easy to understand and have clear relationship to the true simulation parameters, and the classifiers themselves are simple enough that it is possible to understand how the classifier came to a given classification for a given source. LR is particularly simple, and similar enough in performance to XGB that it may be the preferable classifier for Faraday complexity estimation. We can examine its weights to find why it predicted a given FDF was simple or complex. For example, in \autoref{fig:misclassified}, a) was classified as complex due to its low maximum value of $|\hat F|$ and its high Euclidean distance from the simple manifold, b) and d) were both classified as simple due to their low Euclidean distance from the simple manifold, and c) was classified as complex due to its high maximum $|\hat F|$ and $W_2$ distance from the simple manifold (though the prediction is very close to the decision boundary because it has a low Euclidean distance from the simple manifold). Interpretability in a classifier is valuable in astronomy, as understanding the limitations and behaviour of our methods is important to ensure that any physical predictions we make from our results are sensible, well-motivated, and consistent with physics.

  \subsection{Complexity and seeming `not simple'}
  \label{sec:faraday-overlap}

    Through this work we found our methods limited by the significant overlap between complex and simple FDFs. Complex FDFs can be consistent with simple FDFs due to close Faraday components or very small amplitudes on the secondary component, and vice versa due to noise.

    % \autoref{fig:livingston-false-negative} is an example of such a classification. Due to this effect we should expect a lower rate of complexity than the true complexity rate. We demonstrated this in \autoref{sec:faraday-results-observed} where our methods predict lower rates of Faraday complexity than the methods of Faraday moments and QU-fitting employed by Livingston and O'Sullivan respectively. Of course, issues like model overfitting (with QU-fitting) or high sensitivity to choice of noise cutoff (with RM-CLEAN and Faraday moments) may also inflate the rate of complexity in the O'Sullivan and Livingston models respectively, so we refrain from stating that either complexity estimation method is \emph{wrong}, just that they do not match. For any given source, both methods may produce plausible but disagreeing results.
    % Surely this is a good place to discuss the merits of being conservative in developing a catalog?  For example, an RM catalogue of high S/N sources could be easily derived with your classifier because it would be conservative to selecting simple sources

    The main failure mode of our classifiers is misclassifying a complex source as simple (\autoref{tab:cm-lr} and \autoref{tab:cm-xgb}). Whether sources with close components or small amplitudes should be considered complex is not clear, since for practical purposes they can be treated as simple: assuming the source is simple yields a very similar RM to the RM of the primary component, and thus would not negatively impact further data products such as an RM grid. The scenarios where we would want a Faraday complexity classifier rather than a polarisation structure model---large-scale analysis and wide-area surveys---do not seem to be disadvantaged by considering such sources simple. Additional sources similar to these are likely hidden in presumably `simple' FDFs by the frequency range and spacing of the observations, just as how these complex sources would be hidden in lower-resolution observations. Note also that misidentification of complex sources as simple is intrinsically a problem with complexity estimation even for models not well-represented by a simple FDF, as complex sources may conspire to appear as a wide range of viable models including simple \citep{sun15comparison}.

    Conversely, high-noise simple FDFs may be consistent with complex FDFs. One key question is how Faraday complexity estimators should behave as the noise increases: should high noise result in a complex prediction or a simple prediction, given that a complex or simple FDF would both be consistent with a noisy FDF? Occam's razor suggests that we should choose the simplest suitable model, and so increasing noise should lead to predictions of less complexity. This is not how our classifiers operate, however: high-noise FDFs are different to the model simple FDFs and so are predicted to be `not simple'. In some sense our classifiers are not looking for complex sources, but are rather looking for `not simple' sources.

  \subsection{Limitations}
  \label{sec:faraday-limitations}

    Our main limitations are our simplifying assumptions on FDFs and the domain gap between simulated and real observations.

    It is unclear what the effect of our simplifying assumptions are on the effectiveness of our simulation. The three main simplifications we think may negatively affect our simulations are 1) limiting to two components, 2) assuming no external Faraday dispersion, and 3) assuming no internal Faraday dispersion (Faraday thickness). Future work will explore removing these simplifying assumptions, but will need to account for the increased difficulty in characterising the simulation with more components and no longer having Faraday screens as components. Additionally, more work will be required to make sure that the rates of internal and external Faraday dispersion match what might be expected from real sources, or risk making a simulation that has too large a range of consistent models for a given source: for example, a two-component source could also be explained as a sufficiently wide or resolved-out Faraday thick source or a three-component source with a small third component. This greatly complicates the classification task.

    Previous machine learning work \citep[e.g.][]{brown_classifying_2018} has not been run before on real FDF data, so this chapter is the first example of the domain gap arising in Faraday complexity classification. This is a problem that requires further research to solve. We have no good way to ensure that our simulation matches reality, so some amount of domain adaptation will always be necessary to train classifiers on simulated data and then apply these classifiers to real data. But with the low source counts in polarisation science (high-resolution spectropolarimetric data currently numbers in the few hundreds) any machine learning method will need to be trained on simulations. This is not just a problem in Faraday complexity estimation, and domain adaptation is also an issue faced in the wider astroinformatics community: large quantities of labelled data are hard to come by, and some sources are very rare \citep[e.g. gravitational wave detections or fast radio bursts;][]{zevin17gravityspy, gebhard19convolutional, agarwal20fetch}. LR seems to handle the domain adaptation better than XGB, with only a slightly lower accuracy on simulated data. Our results are plausible and the distribution of our simulation well overlaps the distribution of our real data (\autoref{fig:pca}).

    % \autoref{fig:acc-noise} demonstrates that the accuracy of our classifiers is dependent on the amount of noise in the simulated FDF in a surprising way: the correlation between noise and accuracy is not monotonic, and instead accuracy \emph{increases} as the noise increases up to the mean noise level of the training set. The classifier is forced to generalise over different amounts of noise with no good way to estimate how much noise is in a given FDF. This could be remedied by including noise as a feature, as suggested by \autoref{fig:acc-noise-retrained} which shows improved classifier behaviour when the training set was divided into different amounts of noise and the classifier was only trained and validated on FDFs with similar amounts of noise. But this is hard to generalise to real data: we would need not only a reliable noise estimate, but a reliable noise estimate that behaves in the same way to the simulated noise. The mean noise of the Livingston data was $0.028_{-0.022}^{+0.024}$, much lower than our simulated noise. This, combined with the fact that our simulated FDFs look very similar to the observed FDFs, suggests that either or both a) the injected noise and real noise have different units, or b) important aspects of the observed data are not captured by our simulation. This is another example of the domain gap in action and further research is required to unify the simulated and observed noise. The amount of noise can then be included as a feature for the classifier, which could greatly improve performance on both simulated and observed data.

\section{Conclusion}
\label{sec:faraday-conclusion}

  We developed a simple, interpretable machine learning method for estimating Faraday complexity. Our interpretable features were derived by comparing observed FDFs to idealised simple FDFs, which we could determine both for simulated and real observations. We demonstrated the effectiveness of our method on both simulated and real data. Using simulated data, we found that our classifiers were 95 per cent accurate, with near perfect recall of Faraday simple sources (specificity). On simulated data that matched existing observations, our classifiers obtained an accuracy of 90 per cent. Evaluating our classifiers on real data gave plausible results. Future work will need to narrow the domain gap to improve transfer of classifiers trained on simulations to real, observed data.

  % If we were to run our classifiers at scale on the upcoming POSSUM survey, how would the limitations presented in \autoref{sec:faraday-results-simulated} affect derived statistics of Faraday complexity?

  % \begin{itemize}
  %   \item Mention Brown cuts. What are the implications for POSSUM if we were to use our classifier? How does this affect what we can detect and can't?
  % \end{itemize}

  % \begin{itemize}
  %   \item (10) is a good example of noise being important but we can't explicitly factor it in yet - this is two peaks that are very different scales
  %   \item (27) is funky, we get a smooth-looking FDF but it's not obviously two peaks. see also (47)
  %   \item (38) has $\phi_s$ outside of the range! but it still looks good
  % \end{itemize}


\appendix

  \section{2-Wasserstein begets Faraday moments}
  \label{sec:faraday-w2-to-faraday-moments}
    Minimising the 2-Wasserstein distance between a model FDF and the simple manifold gives the second Faraday moment of that FDF. Let $\tilde F$ be the sum-normalised model FDF and let $\tilde S$ be the sum-normalised simple model FDF:
    \begin{align}
      \tilde F(\phi) &= \frac{A_0 \delta(\phi - \phi_0) + A_1 \delta(\phi - \phi_1)}{A_0 + A_1}\\
      \tilde S(\phi; \phi_w) &= \delta(\phi - \phi_w).
    \end{align}
    The $W_2$ distance, usually defined on probability distributions, can be extended to one-dimensional complex functions $A$ and $B$ by normalising them:
      \begin{align}
        \label{eq:faraday-w2}
        D_{W_2}\infdivx{A}{B}^2 &= \inf_{\gamma \in \Gamma(A, B)} \iint_{\phi_{\min}}^{\phi_{\max}} |x - y|^2\ \mathrm{d}\gamma(x, y) \\
        \label{eq:faraday-normalised}
        \tilde A(\phi) &= \frac{|A(\phi)|}{\int_{\phi_{\min}}^{\phi_{\max}} |A(\theta)|\ \mathrm{d}\theta}\\
        \tilde B(\phi) &= \frac{|B(\phi)|}{\int_{\phi_{\min}}^{\phi_{\max}} |B(\theta)|\ \mathrm{d}\theta}
      \end{align}
      where $\Gamma(A, B)$ is the set of couplings of $A$ and $B$, i.e. the set of joint probability distributions that marginalise to $A$ and $B$; and $\inf_{\gamma \in \Gamma(A, B)}$ is the infimum over $\Gamma(A, B)$. This can be interpreted as the minimum cost to `move' one probability distribution to the other, where the cost of moving one unit of probability mass is the squared distance it is moved.

    The set of couplings $\Gamma(\tilde F, \tilde S)$ is the set of all joint probability distributions $\gamma$ such that
    \begin{align}
      \int_{\phi_{\min}}^{\phi_{\max}} \gamma(\phi, \varphi)\ \mathrm{d}\phi &= \tilde S(\varphi; \phi_w),\\
      \int_{\phi_{\min}}^{\phi_{\max}} \gamma(\phi, \varphi)\ \mathrm{d}\varphi &= \tilde F(\phi).
    \end{align}
    The coupling that minimises the integral in \autoref{eq:faraday-w2} will be the optimal transport plan between $\tilde F$ and $\tilde S$. Since $\tilde F$ and $\tilde S$ are defined in terms of delta functions, the optimal transport problem reduces to a discrete optimal transport problem and the optimal transport plan is:
    \begin{equation}
      \gamma(\phi, \varphi) = \frac{A_0 \delta(\phi - \phi_0) + A_1 \delta(\phi - \phi_1)}{A_0 + A_1} \delta(\varphi - \phi_w).
    \end{equation}
    In other words, to move the probability mass of $\tilde S$ to $\tilde F$, a fraction $A_0/(A_0 + A_1)$ is moved from $\phi_w$ to $\phi_0$ and the complementary fraction $A_1/(A_0 + A_1)$ is moved from $\phi_w$ to $\phi_1$. Then:
    \begin{align}
      D_{W_2}\infdivx{\tilde F}{\tilde S}^2 &= \iint_{\phi_{\min}}^{\phi_{\max}} |\phi - \varphi|^2\ \mathrm{d}\gamma(\phi, \varphi)\\
        % &= \frac{\iint_{\phi_{\min}}^{\phi_{\max}} (A_0 \delta(\phi - \phi_0) + A_1 \delta(\phi - \phi_1)) \delta(\varphi - \phi_w) (\phi - \varphi)^2\ \mathrm{d}\phi\ \mathrm{d}\varphi}{A_0 + A_1}\\
        % &= \frac{\int_{\phi_{\min}}^{\phi_{\max}} (A_0 \delta(\phi - \phi_0) + A_1 \delta(\phi - \phi_1)) (\phi - \phi_w)^2\ \mathrm{d}\phi}{A_0 + A_1}\\
        &= \frac{A_0 (\phi_0 - \phi_w)^2 + A_1 (\phi_1 - \phi_w)^2}{A_0 + A_1}.
    \end{align}
    To obtain the $W_2$ distance to the simple manifold, we need to minimise this over $\phi_w$. Differentiate with respect to $\phi_w$ and set equal to zero to find
    \begin{equation}
      \phi_w = \frac{A_0 \phi_0 + A_1 \phi_1}{A_0 + A_1}.
    \end{equation}
    Substituting this back in, we find
    \begin{align}
      \varsigma_{W_2}(F)^2 &= \frac{A_0 A_1}{A_0 + A_1}(\phi_0 - \phi_1)^2
    \end{align}
    which is the Faraday moment.

\section{Euclidean distance in the no-RMSF case}
\label{sec:faraday-euclidean-calculation}

  In this section we calculate the minimumised Euclidean distance evaluated on a model FDF (\autoref{eq:faraday-true-fdf}). Let $\tilde F$ be the sum-normalised model FDF and let $\tilde S$ be the normalised simple model FDF:
  \begin{align}
    \tilde F(\phi) &= \frac{A_0 \delta(\phi - \phi_0) + A_1 \delta(\phi - \phi_1)}{A_0 + A_1}\\
    \tilde S(\phi; \phi_e) &= \delta(\phi - \phi_e).
  \end{align}

  The Euclidean distance between $\tilde F$ and $\tilde S$ is then
  \begin{align}
    &D_E\infdivx{\tilde F(\phi)}{\tilde S(\phi; \phi_e)}^2\\
    &= \int_{\phi_{\min}}^{\phi_{\max}} \left|\tilde F(\phi) - \delta(\phi - \phi_e) \right|^2\ \mathrm{d}\phi.
  \end{align}

  Assume $\phi_0 \neq \phi_1$ (otherwise, $D_E$ will always be either $0$ or $2$). If $\phi_e = \phi_0$, then
  \begin{align}
    &D_E\infdivx{\tilde F(\phi)}{\tilde S(\phi; \phi_e)}^2\\
      &= \frac{1}{(A_0 + A_1)^2} \int_{\phi_{\min}}^{\phi_{\max}} A_1^2 \left|\delta(\phi - \phi_1) - \delta(\phi - \phi_0) \right|^2\ \mathrm{d}\phi\\
      &= \frac{2 A_1^2}{(A_0 + A_1)^2}
  \end{align}
  and similarly for $\phi_e = \phi_1$. If $\phi_e \neq \phi_0$ and $\phi_e \neq \phi_1$, then
  \begin{equation}
    D_E\infdivx{\tilde F(\phi)}{\tilde S(\phi; \phi_e)}^2 = \frac{A_0^2 + A_1^2 + 1}{(A_0 + A_1)^2}.
  \end{equation}
  The minimised Euclidean distance when $\phi_0 \neq \phi_1$ is therefore
  \begin{align}
      D_E(F) &= \min_{\phi_e \in \mathbb{R}} D_E\infdivx{F(\phi)}{F_{\mathrm{simple}}(\phi; \phi_e)}\\
          &= \sqrt{2} \frac{\min(A_0, A_1)}{A_0 + A_1}.
  \end{align}
  If $\phi_0 = \phi_1$, then the minimised Euclidean distance is 0.

% \section{Minimisation over simple FDFs}
% \label{sec:faraday-minimisation}

%   As part of our method, we need to minimise a divergence function $D_f$ over the manifold of simple FDFs $\hat F_{\mathrm{simple}}$:
%   \begin{equation}
%       \varsigma_f(\hat F) = \min_{\phi_w \in \mathbb{R}} D_f\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_s)}.
%   \end{equation}
%   To do this, we perform a two-step approach. This two-step approach allows us to find a smooth (i.e. not discretised) minimum without encountering local minima due to the non-convexity of the optimisation target. First, we generate 1~000 noise-free simple FDFs using the same frequencies as those used to observe $\hat F$, with $\sigma = 0$ and $\phi_0 \in \{\phi_{\min}, \phi_{\min} + \delta\phi, \dots, \phi_{\max}\}$. This is a discrete representation of the simple manifold. We then evaluate $D_f$ between our observed FDF $\hat F$ and these simple spectra and identify the $\phi_0$ that gives us the smallest value of $D_f\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_0)}$. Call this $\phi_0^{(1)}$. This gives us an initial guess at the minimising value of $\phi_s$ in \autoref{eq:faraday-complexity-model}. Second, we use \texttt{scipy.optimize.fmin\textunderscore{}bfgs} to minimise $D_f\infdivx{\hat F(\phi)}{\hat F_{\mathrm{simple}}(\phi; \phi_s)}$ over $\phi_s$ using $\phi_0^{(1)}$ as an initial value, producing a new minimiser $\phi_0^{(2)}$.

\section{Hyperparameters for LR and XGB}
\label{sec:faraday-hyperparameters}

  This section contains tables of the hyperparameters that we used for our classifiers. \autoref{tab:hyperparameters-xgb} and \autoref{tab:hyperparameters-lr} tabulate the hyperparameters for XGB and LR respectively for the ATCA dataset. \autoref{tab:hyperparameters-xgb-askap12} and \autoref{tab:hyperparameters-lr-askap12} tabulate the hyperparameters for XGB and LR respectively for the ASKAP dataset.

  \begin{table}
    \caption{\label{tab:hyperparameters-xgb} XGB hyperparameters for the ATCA dataset.}
    \begin{tabular}{ll}
      \hline\hline
      Parameter & Value\\\hline
      colsample\textunderscore{}bytree & 0.912\\
      gamma & 0.532\\
      learning\textunderscore{}rate & 0.1\\
      max\textunderscore{}depth & 7\\
      min\textunderscore{}child\textunderscore{}weight & 2\\
      scale\textunderscore{}pos\textunderscore{}weight & 1\\
      subsample & 0.557\\
      n\textunderscore{}estimators & 135\\
      reg\textunderscore{}alpha & 0.968\\
      reg\textunderscore{}lambda & 1.420\\
      \hline\hline
    \end{tabular}
  \end{table}

  \begin{table}
    \caption{\label{tab:hyperparameters-lr} LR hyperparameters for the ATCA dataset.}
    \begin{tabular}{ll}
      \hline\hline
      Parameter & Value\\\hline
      penalty & L1\\
      C & 1.668\\
      \hline\hline
    \end{tabular}
  \end{table}

  \begin{table}
    \caption{\label{tab:hyperparameters-xgb-askap12} XGB hyperparameters for the ASKAP dataset.}
    \begin{tabular}{ll}
      \hline\hline
      Parameter & Value\\\hline
      colsample\textunderscore{}bytree & 0.865\\
      gamma & 0.256\\
      learning\textunderscore{}rate & 0.1\\
      max\textunderscore{}depth & 6\\
      min\textunderscore{}child\textunderscore{}weight & 1\\
      scale\textunderscore{}pos\textunderscore{}weight & 1\\
      subsample & 0.819\\
      n\textunderscore{}estimators & 108\\
      reg\textunderscore{}alpha & 0.049\\
      reg\textunderscore{}lambda & 0.454\\
      \hline\hline
    \end{tabular}
  \end{table}

  \begin{table}
    \caption{\label{tab:hyperparameters-lr-askap12} LR hyperparameters for the ASKAP dataset.}
    \begin{tabular}{ll}
      \hline\hline
      Parameter & Value\\\hline
      penalty & L2\\
      C & 0.464\\
      \hline\hline
    \end{tabular}
  \end{table}

\section{Confusion matrices}
\label{sec:faraday-cms}

  This section contains confusion matrices for our classifiers evaluated on simulated ATCA and ASKAP data, as well as a confusion matrix from the state-of-the-art CNN classifier on simulated ASKAP data. \autoref{tab:cm-lr-askap12}, \autoref{tab:cm-lr-askap12}, and \autoref{tab:cm-brown} are confusion matrices on the ASKAP data for LR, XGB, and CNN respectively. \autoref{tab:cm-lr} and \autoref{tab:cm-xgb} are confusion matrices on the ATCA data for LR and XGB respectively.

    \begin{table}
      \caption{\label{tab:cm-lr-askap12} Logistic regression confusion matrix for the ASKAP simulation.}
      \begin{tabular}{r|cc}
        \hline\hline
        & Pred. simple & Pred. complex \\\hline
        True simple & 0.99 & 0.01 \\
        True complex & 0.10 & 0.90 \\
        \hline\hline
      \end{tabular}\\
      \\
      \caption{\label{tab:cm-xgb-askap12} XGB confusion matrix for the ASKAP simulation.}
      \begin{tabular}{r|cc}
        \hline\hline
        & Pred. simple & Pred. complex \\\hline
        True simple & 0.99 & 0.01 \\
        True complex & 0.09 & 0.91 \\
        \hline\hline
      \end{tabular}\\
      \\
      \caption{\label{tab:cm-brown} CNN confusion matrix for the ASKAP simulation, adapted from \citet{brown_classifying_2018}.}
      \begin{tabular}{r|cc}
        \hline\hline
        & Pred. simple & Pred. complex \\\hline
        True simple & 0.97 & 0.03 \\
        True complex & 0.07 & 0.93 \\
        \hline\hline
      \end{tabular}
    \end{table}

    \begin{table}
      \caption{\label{tab:cm-lr} Logistic regression confusion matrix for the ATCA dataset.}
      \begin{tabular}{r|cc}
        \hline\hline
        & Pred. simple & Pred. complex \\\hline
        True simple & 0.92 & 0.08 \\
        True complex & 0.16 & 0.84 \\
        \hline\hline
      \end{tabular}\\
      \\
      \caption{\label{tab:cm-xgb} XGB confusion matrix for the ATCA dataset.}
      \begin{tabular}{r|cc}
        \hline\hline
        & Pred. simple & Pred. complex \\\hline
        True simple & 0.91 & 0.09 \\
        True complex & 0.10 & 0.90 \\
        \hline\hline
      \end{tabular}
    \end{table}

\section{Predictions on real data}
\label{sec:faraday-real-data-fig}

  This section contains \autoref{fig:all-observed-fdfs-lr} and \autoref{fig:all-observed-fdfs-xgb}, which shows the predicted probability of being Faraday complex for all real data used in this chapter, drawn from Livingston et al. (in prep.) and \citet{osullivan_broad-band_2017}.

  \begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{faraday-images/both_spectra_lr.pdf}
    % \includegraphics[width=0.7\linewidth]{faraday-images/jack_spectra.pdf}
    \caption{The 142 observed FDFs ordered by LR-estimated probability of being Faraday complex. Livingston-identified components are shown in orange while O'Sullivan-identified components are shown in magenta. Simpler FDFs are shown in purple while more complex FDFs are shown in green, and the numbers overlaid indicate the XGB estimate. A lower number indicates a lower probability that the corresponding source is complex, i.e. lower numbers correspond to simpler spectra.}
    \label{fig:all-observed-fdfs-lr}
  \end{figure*}

  \begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{faraday-images/both_spectra_xgb.pdf}
    % \includegraphics[width=0.7\linewidth]{faraday-images/jack_spectra.pdf}
    \caption{The 142 observed FDFs ordered by XGB-estimated probability of being Faraday complex. Livingston-identified components are shown in orange while O'Sullivan-identified components are shown in magenta. Simpler FDFs are shown in purple while more complex FDFs are shown in green, and the numbers overlaid indicate the XGB estimate. A lower number indicates a lower probability that the corresponding source is complex, i.e. lower numbers correspond to simpler spectra.}
    \label{fig:all-observed-fdfs-xgb}
  \end{figure*}

\section{Simulating observed FDFs}
\label{sec:faraday-simulating}

  We simulated FDFs by approximating them by arrays of complex numbers. An FDF $F$ is approximated on the domain $[-\phi_{\max}, \phi_{\max}]$ by a vector $\vec F \in \mathbb R^d$:
    \begin{equation}
      \label{eq:faraday-vec-f}
      \vec F_j = \sum_{k = 0}^1 A_k \delta(-\phi_{\max} + j \delta \phi - \phi_k)
    \end{equation}
    where $\delta\phi = (\phi_{\max} - \phi_{\min}) / d$ and $d$ is the number of Faraday depth samples in the FDF.
    $\vec F$ is sampled by uniformly sampling its parameters:
    \begin{align}
      \label{eq:faraday-model-distributions}
      % p(\phi_0, \phi_1, A_0, A_1) = \frac{1}{(\phi_{\max} - \phi_{\min})^2} \begin{cases}
      %   1 & \phi_{0,1} \in [\phi_{\min} \phi_{\max}],\\
      %     & A_{0, 1} \in [0, 1];\\
      %   0 & \mathrm{otherwise}.
      % \end{cases}
      % p(\phi_k) &= \frac{1}{\phi_{\max} - \phi_{\min}} \begin{cases}
      %   1 & \phi_k \in [\phi_{\min} \phi_{\max}],\\
      %   0 & \mathrm{otherwise};
      % \end{cases}\\
      % p(A_k) &= \begin{cases}
      %   1 & \phi_k \in [0, 1],\\
      %   0 & \mathrm{otherwise};
      % \end{cases}
      \phi_k &\in [\phi_{\min}, \phi_{\min} + \delta\phi, \dots, \phi_{\max}]\\
      A_k &\sim \mathcal U(0, 1).
    \end{align}
    We then generate a vector polarisation spectrum $\vec P \in \mathbb R^m$ from $\vec F$ using a \autoref{eq:faraday-discrete-f-to-p}:
    \begin{equation}
      \label{eq:faraday-discrete-f-to-p}
      \vec P_\ell = \sum_{j = 0}^{j} F_j e^{2i(\phi_{\min} + j\delta_\phi)\lambda^2_\ell}\ \mathrm{d}\phi.
    \end{equation}
    $\lambda^2_\ell$ is the discretised value of $\lambda^2$ at the $\ell$th index of $\vec P$. This requires a set of $\lambda^2$ values, which depends on the dataset being simulated. These values can be treated as the channel wavelengths at which the polarisation spectrum was observed. We then add Gaussian noise with variance $\sigma^2$ to each element of $\vec P$ to obtain a discretised noisy observation $\hat{\vec{P}}$. Finally, we perform RM synthesis using the Canadian Initiative for Radio Astronomy Data Analysis \texttt{RM} package\footnote{\url{https://github.com/CIRADA-Tools/RM}}, which is a \texttt{Python} module that implements a discrete version of RM synthesis:
    \begin{equation}
      \label{eq:faraday-discrete-rm-synthesis}
      \hat{\vec{F}}_j = m^{-1} \sum_{\ell = 1}^m \vec{\hat P}_\ell e^{-2i(\phi_{\min} + j\delta_\phi)\lambda^2_\ell}.
    \end{equation}

\unappendix

  % If we were to run our classifiers at scale on the upcoming POSSUM survey, how would the limitations presented in \autoref{sec:faraday-results-simulated} affect derived statistics of Faraday complexity? 

  % \begin{itemize}
  %   \item Mention Brown cuts. What are the implications for POSSUM if we were to use our classifier? How does this affect what we can detect and can't?
  % \end{itemize}

  % \begin{itemize}
  %   \item (10) is a good example of noise being important but we can't explicitly factor it in yet - this is two peaks that are very different scales
  %   \item (27) is funky, we get a smooth-looking FDF but it's not obviously two peaks. see also (47)
  %   \item (38) has $\phi_s$ outside of the range! but it still looks good
  % \end{itemize}